<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A-Z Cloud – Documentation</title>
    <link>https://dsc-vjti.github.io/a-z-cloud/docs/</link>
    <description>Recent content in Documentation on A-Z Cloud</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="https://dsc-vjti.github.io/a-z-cloud/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Actions by GitHub</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/a/actions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/a/actions/</guid>
      <description>
        
        
        &lt;p&gt;To quickly see GitHub Actions in &lt;em&gt;action&lt;/em&gt;, check out the &lt;code&gt;.github&lt;/code&gt; directory in the source code of this website &lt;a href=&#34;https://github.com/DSC-VJTI/a-z-cloud/tree/main/.github&#34;&gt;here&lt;/a&gt;. You can see the following directory structure:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;.github
├── dependabot.yml
└── workflows
    └── gh-pages.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There is a &lt;code&gt;.yaml&lt;/code&gt; or YAML (which stands for YAML Ain&amp;rsquo;t Markup Language) file that defines some workflow or a set of tasks that will be run on each &lt;em&gt;event&lt;/em&gt; on the GitHub repository.&lt;/p&gt;
&lt;h3 id=&#34;what-is-an-_event_&#34;&gt;What is an &lt;em&gt;event&lt;/em&gt;?&lt;/h3&gt;
&lt;p&gt;An event is a specific change made to your GitHub repository that should trigger your desired workflow. This event can be a new push, a new issue or a pull request made to the repository.&lt;/p&gt;
&lt;h3 id=&#34;what-is-a-_workflow_&#34;&gt;What is a &lt;em&gt;workflow&lt;/em&gt;?&lt;/h3&gt;
&lt;p&gt;A set of automated tasks that are to be run of a specific event. A workflow is composed of several &lt;em&gt;jobs&lt;/em&gt; and is defined in a YAML file such as specified above with &lt;code&gt;gh-pages.yaml&lt;/code&gt;. This is how this file looks:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;GitHub Pages&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;on&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;push&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;branches&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;main&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Set a branch to deploy&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;pull_request&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;jobs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;deploy&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;runs-on&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ubuntu-20.04&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;concurrency&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;group&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;${{ github.workflow }}-${{ github.ref }}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;steps&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;uses&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;actions/checkout@v3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;with&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;submodules&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Fetch Hugo themes (true OR recursive)&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;fetch-depth&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Fetch all history for .GitInfo and .Lastmod&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Setup Hugo&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;uses&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;peaceiris/actions-hugo@v2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;with&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hugo-version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;latest&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;extended&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Build&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;run&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;git submodule update --init --recursive --depth 1 &amp;amp;&amp;amp; npm i &amp;amp;&amp;amp; hugo&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Deploy&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;uses&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;peaceiris/actions-gh-pages@v3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;${{ github.ref == &amp;#39;refs/heads/main&amp;#39; }}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;with&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;github_token&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;${{ secrets.GITHUB_TOKEN }}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;publish_dir&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;./public&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There are 2 keywords to focus on in this file - &lt;strong&gt;on&lt;/strong&gt; and &lt;strong&gt;jobs&lt;/strong&gt;. &lt;strong&gt;on&lt;/strong&gt; is where you define the event/s that should trigger this workflow and &lt;strong&gt;jobs&lt;/strong&gt; are the set of tasks that should execute as a part of the workflow.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;GitHub Actions is a powerful tool to have in your development arsenal. Learn more from the official &lt;a href=&#34;https://docs.github.com/en/actions&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: App Engine by Google Cloud Platform</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/a/app-engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/a/app-engine/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;A fully managed environment lets you focus on code while App Engine manages infrastructure concerns.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Google App Engine is a Platform-as-a-Service for deploying and managing web applications for Go, PHP, Python, Ruby, .NET, and Node.js runtimes along with custom runtimes. It offers autoscaling, cloud monitoring and logging services with the ability to define access rules for your web application.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Try out App Engine by deploying a Flask web application with this &lt;a href=&#34;https://codelabs.developers.google.com/codelabs/cloud-app-engine-python3#0&#34;&gt;codelab&lt;/a&gt;!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: BigQuery</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/b/big-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/b/big-query/</guid>
      <description>
        
        
        &lt;p&gt;BigQuery&amp;rsquo;s serverless infrastructure lets you focus on your data instead of resource management. BigQuery combines a cloud-based data warehouse and powerful analytic tools.&lt;/p&gt;
&lt;h3 id=&#34;bigquery-storage&#34;&gt;BigQuery storage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;BigQuery stores data using a columnar storage format that is optimized for analytical queries.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BigQuery presents data in tables, rows, and columns and provides full support for database transaction semantics (ACID).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BigQuery storage is automatically replicated across multiple locations to provide high availability.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bigquery-analytics&#34;&gt;BigQuery analytics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Descriptive and prescriptive analysis uses include business intelligence, ad hoc analysis, geospatial analytics, and machine learning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can query data stored in BigQuery or run queries on data where it lives using external tables or federated queries including Cloud Storage, Bigtable, Spanner, or Google Sheets stored in Google Drive.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more from the official &lt;a href=&#34;https://cloud.google.com/bigquery/docs/storage_overview&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: BigTable</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/b/big-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/b/big-table/</guid>
      <description>
        
        
        &lt;p&gt;Cloud Bigtable is a sparsely populated table that can scale to billions of rows and thousands of columns, enabling you to store terabytes or even petabytes of data. A single value in each row is indexed; this value is known as the row key. Bigtable is ideal for storing very large amounts of single-keyed data with very low latency. It supports high read and write throughput at low latency, and it is an ideal data source for MapReduce operations.&lt;/p&gt;
&lt;p&gt;Bigtable is exposed to applications through multiple client libraries, including a supported extension to the Apache HBase library for Java. As a result, it integrates with the existing Apache ecosystem of open-source Big Data software.&lt;/p&gt;
&lt;p&gt;Bigtable&amp;rsquo;s powerful back-end servers offer several key advantages over a self-managed HBase installation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Incredible scalability&lt;/strong&gt; Bigtable scales in direct proportion to the number of machines in your cluster. A self-managed HBase installation has a design bottleneck that limits the performance after a certain threshold is reached. Bigtable does not have this bottleneck, so you can scale your cluster up to handle more reads and writes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simple administration&lt;/strong&gt; Bigtable handles upgrades and restarts transparently, and it automatically maintains high data durability. To replicate your data, simply add a second cluster to your instance, and replication starts automatically. No more managing replicas or regions; just design your table schemas, and Bigtable will handle the rest for you.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cluster resizing without downtime&lt;/strong&gt; You can increase the size of a Bigtable cluster for a few hours to handle a large load, then reduce the cluster&amp;rsquo;s size again—all without any downtime. After you change a cluster&amp;rsquo;s size, it typically takes just a few minutes under load for Bigtable to balance performance across all of the nodes in your cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more from the official &lt;a href=&#34;https://cloud.google.com/bigtable/docs/overview#what-its-good-for&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cloud Build by Google Cloud Platform</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/c/cloud-build/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/c/cloud-build/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Implementing containerization has inspired organizations to maximize managed cloud infrastructures like Cloud Build to speedily build, test and deploy container images.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Cloud Build is a service that executes your builds on Google Cloud.&lt;/p&gt;
&lt;p&gt;Cloud Build can import source code from a variety of repositories or cloud storage spaces, execute a build to your specifications, and produce artifacts such as Docker containers or Java archives.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about Cloud build in GCP from the official &lt;a href=&#34;https://cloud.google.com/build/docs/overview&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Try out Continuous deployment to Google Kubernetes Engine (GKE) with Cloud Build from this &lt;a href=&#34;https://codelabs.developers.google.com/codelabs/cloud-builder-gke-continuous-deploy#0&#34;&gt;codelab&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cloud Load Balancing</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/l/cloud-load-balancing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/l/cloud-load-balancing/</guid>
      <description>
        
        
        &lt;p&gt;Load balancers are managed services on GCP that distribute traffic across multiple instances of your application. GCP bears the burden of managing operational overhead and reduces the risk of having a non-functional, slow, or overburdened application.
With Google Cloud Load Balancing, you can serve content as close as possible to your users, on a system that can respond to over 1 million queries per second!&lt;/p&gt;
&lt;h3 id=&#34;different-load-balancing-options&#34;&gt;Different load balancing options&lt;/h3&gt;
&lt;p&gt;To decide which load balancer best suits your implementation, you need to think about whether you need&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Global&lt;/strong&gt; or &lt;strong&gt;regional&lt;/strong&gt; load balancing. Global load balancing means backend endpoints live in multiple regions. Regional load balancing means backend endpoints live in a single region.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;External&lt;/strong&gt; or &lt;strong&gt;internal&lt;/strong&gt; load balancing&lt;/li&gt;
&lt;li&gt;What &lt;strong&gt;type of traffic&lt;/strong&gt; you are serving? HTTP, HTTPS, SSL, TCP, UDP etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;external-load-balancer&#34;&gt;External load balancer&lt;/h4&gt;
&lt;p&gt;External load balancing includes four options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP(S) Load Balancing for HTTP or HTTPS traffic,&lt;/li&gt;
&lt;li&gt;TCP Proxy for TCP traffic for ports other than 80 and 8080, without SSL offload&lt;/li&gt;
&lt;li&gt;SSL Proxy for SSL offload on ports other than 80 or 8080.&lt;/li&gt;
&lt;li&gt;Network Load Balancing for TCP/UDP traffic.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;h5 id=&#34;https-load-balancers&#34;&gt;HTTP(S) load balancers&lt;/h5&gt;
&lt;p&gt;Global HTTP(S) load balancing if for layer-7 traffic
Google pushed load balancing out to the edge network on front-end servers, as opposed to using the traditional DNS-based approach. Thus, global load-balancing capacity can be behind a single Anycast virtual IPv4 or IPv6 address. This means you can deploy capacity in multiple regions without having to modify the DNS entries or add new load balancer IP address for new regions. So, it is clear that with global HTTP(S) load balancing, you get cross-region failover and overflow!&lt;/p&gt;
&lt;p&gt;With global HTTP(S) load balancing, you get cross-region failover and overflow!
The distribution algorithm automatically directs traffic to the next closest instance with available capacity in the event of failure of or lack of capacity for instances in the region closest to end user.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h5 id=&#34;proxy-based-load-balancers-tcp-and-ssl&#34;&gt;Proxy based load balancers (TCP and SSL)&lt;/h5&gt;
&lt;p&gt;Google Cloud also offers proxy-based load balancers for TCP and SSL traffic, and they use the same globally distributed infrastructure.
Use TCP proxy load balancer when you are dealing with TCP traffic and do not need SSL offload.
Generally speaking, your decision to use them would depend on whether you require SSL offload or not. You can find out more in the links below.
Use SSL proxy load balancer when you are dealing with TCP traffic and need SSL offload.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h5 id=&#34;network-load-balancer&#34;&gt;Network load balancer&lt;/h5&gt;
&lt;p&gt;While the global HTTP(S) load balancer is for Layer-7 traffic and is built using the Google Front End Engines at the edge of Google’s network, the regional Network Load Balancer is for Layer-4 traffic and is built using Maglev.
Network load balancer is for the Layer-4 traffic.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;internal-load-balancer&#34;&gt;Internal Load Balancer&lt;/h4&gt;
&lt;p&gt;With internal load balancing, you can run your applications behind an internal IP address and disperse HTTP/HTTPs traffic to your backend application hosted either on Google Kubernetes Engine (GKE) or Google Compute Engine (GCE).
The internal load balancer is a managed service that can only be accessed on an internal IP address and in the chosen region of your Virtual Private Cloud network. You can use it to route and balance load traffic to your virtual machines.&lt;/p&gt;
&lt;p&gt;Similar to the HTTP(S) Load Balancer and Network Load Balancer, Internal L7 load balancer is neither a hardware appliance nor an instance-based solution, and can support as many connections per second as you need since there’s no load balancer in the path between your client and backend instances.
Internal layer 7 load balancer can support as many connections per second as your need!&lt;/p&gt;
&lt;p align = &#34;center&#34;&gt;
&lt;img src = &#34;https://miro.medium.com/max/1400/1*TTUArfpyYhGvsoLJaLrzaA.png&#34; alt=&#34;load balancing architecture&#34; width=&#34;800&#34; height=&#34;500&#34;&gt;
&lt;/p&gt;
&lt;p align = &#34;center&#34;&gt;
The architecture for your website Beyond Treat (your one stop shop for vegan dog treats) would look something like this with an internal load balancer for the internal traffic, external global HTTPS load balancer for the incoming traffic.
&lt;/p&gt;   
&lt;br/&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about Cloud Load Balancing from the official &lt;a href=&#34;https://cloud.google.com/load-balancing/docs/load-balancing-overview&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Explore Cloud Load Balancing with the following codelabs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://codelabs.developers.google.com/codelabs/cloud-webapp-hosting-gce#5&#34;&gt;Host and scale a web app in Google Cloud with Compute Engine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kiosk-dot-codelabs-site.appspot.com/codelabs/cloud-load-balancers/index.html?index=..%2F..index#0&#34;&gt;Setup Network and HTTP Load Balancers&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cloud Monitoring</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/h/cloud_monitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/h/cloud_monitoring/</guid>
      <description>
        
        
        &lt;p&gt;Cloud monitoring is the process of reviewing and managing the operational workflow and processes within a cloud infrastructure or asset. These techniques confirm the performance of websites, servers, applications, and other cloud infrastructure.&lt;/p&gt;
&lt;p&gt;Cloud Monitoring collects measurements of your service and of the Google Cloud resources that you use.&lt;/p&gt;
&lt;h3 id=&#34;how-it-helps&#34;&gt;How it helps?&lt;/h3&gt;
&lt;p&gt;It:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Monitor CPU and memory details.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Keep tabs on disk utilization.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Achieve maximum network efficiency.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Effectively track firewall metrics.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Track quota metrics with ease.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Helps you to plan ahead with insightful reports.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You can learn more about this by visiting the &lt;a href=&#34;https://cloud.google.com/monitoring/docs/monitoring-overview&#34;&gt;official page&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cloud Run</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/m/cloud-run/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/m/cloud-run/</guid>
      <description>
        
        
        &lt;p&gt;Cloud Run is a fully-managed compute environment for deploying and scaling serverless HTTP containers without worrying about provisioning machines, configuring clusters, or autoscaling.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;https://repository-images.githubusercontent.com/189295422/f294aa00-838c-11e9-8e27-a1fdc651371f&#34; alt=&#34;Cloud Run logo&#34; height=&#34;30%&#34; width=&#34;30%&#34; /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;benefits-of-cloud-run&#34;&gt;Benefits of Cloud Run&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;No vendor lock-in - Because Cloud Run takes standard OCI containers and implements the standard &lt;a href=&#34;https://cloud.google.com/knative&#34;&gt;Knative&lt;/a&gt; Serving API, you can easily port over your applications to on-premises or any other cloud environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fast autoscaling - Microservices deployed in Cloud Run scale automatically based on the number of incoming requests, without you having to configure or manage a full-fledged Kubernetes cluster. Cloud Run scales to zero— that is, uses no resources—if there are no requests.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Split traffic - Cloud Run enables you to split traffic between multiple revisions, so you can perform gradual rollout such as canary deployments or blue/green deployments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Custom domains - You can set up custom domain mapping in Cloud Run and it will provision a TLS certificate for your domain.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Automatic redundancy - Cloud Run offers automatic redundancy so you don’t have to worry about creating multiple instances for high availability&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following is an example of a microservices architecture using Cloud Run and several GCP services:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://storage.googleapis.com/gweb-cloudblog-publish/images/example_ms_a_callout.max-1700x1700.png&#34; alt=&#34;Cloud Run use cases&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Cloud Run &lt;a href=&#34;https://cloud.google.com/run/docs&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hello Cloud Run with Python &lt;a href=&#34;https://codelabs.developers.google.com/codelabs/cloud-run-hello-python3&#34;&gt;codelab&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploy a website with Cloud Run &lt;a href=&#34;https://codelabs.developers.google.com/codelabs/cloud-run-deploy&#34;&gt;codelab&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cloud Scheduler</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/j/cloud-scheduler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/j/cloud-scheduler/</guid>
      <description>
        
        
        &lt;p&gt;Cloud Scheduler is a fully managed enterprise-grade cron &lt;strong&gt;j&lt;/strong&gt;ob scheduler. It allows you to schedule virtually any job, including batch, big data jobs such as ETL, and cloud infrastructure operations. You can automate everything, including retries in case of failure to reduce manual toil and intervention.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;https://storage.googleapis.com/gweb-cloudblog-publish/images/cloud-scheduler-512-color.max-600x600.png&#34; alt=&#34;Cloud Scheduler logo&#34; width=&#34;250&#34; height=&#34;250&#34; /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;leveraging-cloud-scheduler&#34;&gt;Leveraging Cloud Scheduler&lt;/h3&gt;
&lt;p&gt;Cloud Scheduler can be used in the following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reduce minimal manual effort by scheduling repetitive Big Data tasks such as fetching and preprocessing of data for a data pipeline&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Downscale or upscaling cloud infrastructure when needed in a reliable manner&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Automate health checks, trigger a Cloud Pub/Sub pipeline, and a lot more with integration with our GCP services&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Read the &lt;a href=&#34;https://cloud.google.com/scheduler/docs&#34;&gt;documentation&lt;/a&gt; to get started.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check out several &lt;a href=&#34;https://cloud.google.com/scheduler/docs/tut-pub-sub&#34;&gt;tutorials&lt;/a&gt; and give Cloud Scheduler a try!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Containers</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/c/containers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/c/containers/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Containers are lightweight packages of your application code together with dependencies such as specific versions of programming language runtimes and libraries required to run your software services.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;what-are-containers&#34;&gt;What are containers?&lt;/h3&gt;
&lt;p&gt;Containers are packages of software that contain all of the necessary elements to run in any environment. In this way, containers virtualize the operating system and run anywhere, from a private data center to the public cloud or even on a developer’s personal laptop. From Gmail to YouTube to Search, everything at Google runs in containers. Containerization allows our development teams to move fast, deploy software efficiently, and operate at an unprecedented scale.&lt;/p&gt;
&lt;h3 id=&#34;what-are-containers-used-for&#34;&gt;What are containers used for?&lt;/h3&gt;
&lt;p&gt;Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of whether the target environment is a private data center, the public cloud, or even a developer’s personal laptop.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h4 id=&#34;microservices&#34;&gt;Microservices:&lt;/h4&gt;
&lt;p&gt;Containers are small and lightweight, which makes them a good match for microservice architectures where applications are constructed of many, loosely coupled and independently deployable smaller services.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h4 id=&#34;devops&#34;&gt;DevOps:&lt;/h4&gt;
&lt;p&gt;The combination of microservices as an architecture and containers as a platform is a common foundation for many teams that embrace DevOps as the way they build, ship and run software.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h4 id=&#34;hybrid-multi-cloud&#34;&gt;Hybrid, multi-cloud:&lt;/h4&gt;
&lt;p&gt;Because containers can run consistently anywhere, across laptop, on-premises and cloud environments, they are an ideal underlying architecture for hybrid cloud and multicloud scenarios where organizations find themselves operating across a mix of multiple public clouds in combination with their own data center.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h4 id=&#34;application-modernizing-and-migration&#34;&gt;Application modernizing and migration:&lt;/h4&gt;
&lt;p&gt;One of the most common approaches to application modernization starts by containerizing them so that they can be migrated to the cloud.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Docker</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/d/docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/d/docker/</guid>
      <description>
        
        
        &lt;p&gt;Docker provides various services such as the Docker daemon (&lt;code&gt;dockerd&lt;/code&gt;), Docker CLI, and Docker Hub Registry that help package applications in containers and host them. As we learned in &lt;a href=&#34;https://dsc-vjti.github.io/a-z-cloud/a-z-cloud/docs/c/containers/&#34; title=&#34;Containers&#34;&gt;containers&lt;/a&gt;, the several problems of software not being able to run on some machine and portability of software are solved by containers and Docker provides salient tools to make it possible.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Docker_%28container_engine%29_logo.svg/915px-Docker_%28container_engine%29_logo.svg.png&#34; alt=&#34;Docker logo&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;docker-architecture&#34;&gt;Docker architecture&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s discuss the architecture of Docker Engine which comprises of Docker client (CLI), Docker Host that contains the Docker daemon which manages the different containers, and the software that needs to be packaged to a container i.e., an image made available on a registry.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.researchgate.net/profile/Yahya-Al-Dhuraibi/publication/308050257/figure/fig1/AS:433709594746881@1480415833510/High-level-overview-of-Docker-architecture.png&#34; alt=&#34;Docker architecture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;docker-hub&#34;&gt;Docker Hub&lt;/h3&gt;
&lt;p&gt;This is the default registry that Docker uses to fetch &lt;em&gt;images&lt;/em&gt; to be run inside containers. But what is an image? A Docker image is a template file that contains the instructions to create a container. Each image has a base image typically a minimal Linux-based operating system such as Alpine and on top of this image, we can add layers of our own images. This can be done using a &lt;code&gt;Dockerfile&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The following is an example &lt;code&gt;Dockerfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Dockerfile&#34; data-lang=&#34;Dockerfile&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; python:3.7&lt;/span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;LABEL&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;maintainer&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Pankaj Khushalani&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;COPY&lt;/span&gt; ./exercises/python-helloworld /app&lt;span style=&#34;color:#a40000&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;WORKDIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; /app&lt;/span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RUN&lt;/span&gt; pip install -r requirements.txt&lt;span style=&#34;color:#a40000&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;CMD&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;app.py&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Each line contains a keyword following by a flag or a command to be run. In the first line of the &lt;code&gt;Dockerfile&lt;/code&gt;, the base image follows the &lt;code&gt;FROM&lt;/code&gt; keyword. Here, &lt;code&gt;python:3.7&lt;/code&gt; is the name of the base image, which is hosted on Docker Hub and is downloaded when this &lt;code&gt;Dockerfile&lt;/code&gt; is run. &lt;code&gt;python:3.7&lt;/code&gt; contains the Linux-based light-weight OS Alpine which comes with Python version 3.7 installed on it.&lt;/p&gt;
&lt;h3 id=&#34;docker-daemon&#34;&gt;Docker daemon&lt;/h3&gt;
&lt;p&gt;This is the server that hosts and manages the several Docker containers that we would like to run. The communication between different containers is also handled by the daemon. It also plays an important role in creating a Docker container from images pulled from Docker Hub.&lt;/p&gt;
&lt;h3 id=&#34;docker-cli&#34;&gt;Docker CLI&lt;/h3&gt;
&lt;p&gt;You can interact with the Docker daemon using Docker CLI. This includes creating a Docker container from a &lt;code&gt;Dockerfile&lt;/code&gt; or an image directly fetched from Docker Hub, interacting with a Docker container, managing them, etc. You can read the &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/cli/&#34;&gt;documentation&lt;/a&gt; for the list of available commands.&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Install Docker and have a go at it! Docker Engine comes with Docker Desktop for Windows and macOS, while for Linux distributions, Docker Engine can directly be downloaded and used. You can find the installation guide &lt;a href=&#34;https://docs.docker.com/engine/install/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://devopswithdocker.com/&#34;&gt;DevOps with Docker&lt;/a&gt; is an MOOC by the University of Helsinki and a great resource to learn the ins and outs of Docker.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;a href=&#34;https://youtu.be/3c-iBn73dDE&#34;&gt;video tutorial&lt;/a&gt; on Docker from Tech World With Nana&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Eventarc</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/e/eventarc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/e/eventarc/</guid>
      <description>
        
        
        &lt;p&gt;Eventarc allows you to build event-driven architectures without having to implement, customize, or maintain the underlying infrastructure. Eventarc offers a standardized solution to manage the flow of state changes, called events, between decoupled microservices. When triggered, Eventarc routes these events through Pub/Sub subscriptions to various destinations while managing delivery, security, authorization, observability, and error-handling for you.&lt;/p&gt;
&lt;p&gt;You can manage Eventarc from the Google Cloud Console, from the command line using the gcloud CLI, or by using the Eventarc API.&lt;/p&gt;
&lt;h3 id=&#34;benefits-of-eventarc&#34;&gt;Benefits Of Eventarc&lt;/h3&gt;
&lt;p&gt;Eventarc provides an easier path to receive events not only from Pub/Sub topics but from a number of Google Cloud sources with its Audit Log and Pub/Sub integration. Any service with Audit Log integration or any application that can send a message to a Pub/Sub topic can be event sources for Eventarc. You don’t have to worry about the underlying infrastructure with Eventarc. It is a managed service with no clusters to set up or maintain.&lt;/p&gt;
&lt;p&gt;It also has some concrete benefits beyond the easy integration. It provides consistency and structure to how events are generated, routed, and consumed.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Check out the &lt;a href=&#34;https://cloud.google.com/eventarc/docs&#34;&gt;Eventarc documentation&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;A few code samples are available &lt;a href=&#34;https://cloud.google.com/eventarc/docs#code-samples&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Firebase Cloud Functions</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/f/firebase_cloud_functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/f/firebase_cloud_functions/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Cloud Functions for Firebase is a serverless framework that lets you automatically run backend code in response to events triggered by Firebase features and HTTPS requests. Your JavaScript or TypeScript code is stored in Google&amp;rsquo;s cloud and runs in a managed environment. There&amp;rsquo;s no need to manage and scale your own servers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;what-is-firebase-cloud-functions&#34;&gt;What is Firebase Cloud Functions?&lt;/h3&gt;
&lt;p&gt;Firebase Cloud Functions in particular are like Lego blocks that you can connect to any Firebase service. For example, a function can be triggered when an image is uploaded to Firebase Storage to create a thumbnail, or maybe clean some user data when a node is deleted in the Realtime Database. Pretty much anything of interest that happens in Firebase can trigger a function.
If that isn’t enough, you can also use HTTP to trigger functions with GET, POST, etc.&lt;/p&gt;
&lt;h3 id=&#34;how-does-it-work&#34;&gt;How does it work?&lt;/h3&gt;
&lt;p&gt;Cloud Functions for Firebase lets you automatically run backend code in response to events triggered by Firebase features and HTTPS requests. Your code is stored in Google’s cloud and runs in a managed environment. There’s no need to manage and scale your own servers, for example, if we have a chatting mobile app that uses firebase to store the messages and we want to filter the messages before they are written to the database so as to make sure there are no bad words included in any message, before the cloud functions were made that was really hard to achieve and most probably we would need someone to write a backend code to do this check, but today, all we need to do is just write a simple cloud function that triggers whenever any message is added to our database and filter it out.&lt;/p&gt;
&lt;p&gt;It is very powerful especially for mobile developers that have no knowledge on how to write web apps or backend, you can also integrate with third-party APIs like Slack and Github.&lt;/p&gt;
&lt;h3 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h3&gt;
&lt;p&gt;Cloud Functions allows developers access to Google Cloud events and Firebase, along with scalable computing power for running the code in response to those events. It is expected that Firebase applications will use Cloud Functions in unique ways to meet their unique and specific needs, use cases may fall into the following areas:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Notifying users when something interesting happens.&lt;/li&gt;
&lt;li&gt;Performing Realtime Database maintenance and sanitization.&lt;/li&gt;
&lt;li&gt;Executing intensive tasks in the cloud rather than executing in our application.&lt;/li&gt;
&lt;li&gt;Integrate with APIs and third-party services.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about Firebase Cloud Functions from the official &lt;a href=&#34;https://firebase.google.com/docs/functions#:~:text=Cloud%20Functions%20for%20Firebase%20is,runs%20in%20a%20managed%20environment&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Learn Cloud Functions for Firebase with this &lt;a href=&#34;https://firebase.google.com/codelabs/firebase-cloud-functions#0&#34;&gt;codelab&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Google Kubernetes Engine</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/k/google-k8s-engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/k/google-k8s-engine/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;https://techolution.com/wp-content/uploads/2019/05/file-3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Google Kubernetes Engine (GKE) provides a managed environment for deploying, managing, and scaling your containerized applications using Google infrastructure. The GKE environment consists of multiple machines (specifically, Compute Engine instances) grouped together to form a cluster.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Read the &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview&#34;&gt;documentation&lt;/a&gt; to get started.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Google Maps Platform</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/g/google-maps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/g/google-maps/</guid>
      <description>
        
        
        &lt;p&gt;One of the most prominent applications of GIS is Google Maps. Google Cloud Platform provides various services of Google Maps via the &lt;a href=&#34;https://mapsplatform.google.com/&#34;&gt;Google Maps Platform&lt;/a&gt;. It provides SDKs and APIs to effectively use Google Maps in our applications.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://developers.google.com/maps/images/google-maps-platform-1200x675.png&#34; alt=&#34;Google Maps Platform logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;The platform provides APIs in the following categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Maps&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dynamic Maps for JavaScript, Android, iOS&lt;/li&gt;
&lt;li&gt;Dynamic Street View for JavaScript, Android, iOS&lt;/li&gt;
&lt;li&gt;Static Maps API&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Places&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Autocomplete API&lt;/li&gt;
&lt;li&gt;Geocoding API&lt;/li&gt;
&lt;li&gt;Geolocation API&lt;/li&gt;
&lt;li&gt;Place Details API for Android and iOS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Routes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Directions API&lt;/li&gt;
&lt;li&gt;Roads API&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You can learn more about using these SDKs and APIs from the official &lt;a href=&#34;https://developers.google.com/maps/documentation&#34;&gt;documentation&lt;/a&gt; of Google Maps Platform.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://codelabs.developers.google.com/codelabs/advanced-android-kotlin-training-maps#0&#34;&gt;Codelab&lt;/a&gt; on how to add a Google Map to your Android mobile application.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: IaaS offering by GCP - Google Compute Engine</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/i/google-compute-engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/i/google-compute-engine/</guid>
      <description>
        
        
        &lt;h3 id=&#34;what-is-google-compute-engine&#34;&gt;What is Google Compute Engine?&lt;/h3&gt;
&lt;p&gt;Google Compute Engine (GCE) is an Infrastructure as a Service (IaaS) offering that allows clients to run workloads on Google&amp;rsquo;s physical hardware. 
Google Compute Engine provides a scalable number of virtual machines (VMs) to serve as large compute clusters for that purpose.  GCE can be managed through a RESTful API, command line interface (CLI) or Web console. Compute Engine is a pay-per-usage service with a 10-minute minimum. There are no up-front fees or time-period commitments. GCE competes with Amazon&amp;rsquo;s Elastic Compute Cloud (EC2) and Microsoft Azure.&lt;/p&gt;
&lt;p&gt;GCE&amp;rsquo;s application program interface (API) provides administrators with virtual machine, DNS server and load balancing capabilities. VMs are available in a number of CPU and RAM configurations and Linux distributions, including Debian and CentOS. Customers may use their own system images for custom virtual machines. Data at rest is encrypted using the AEC-128-CBC algorithm.&lt;/p&gt;
&lt;p&gt;GCE allows administrators to select the region and zone where certain data resources will be stored and used. Currently, GCE has three regions: United States, Europe and Asia. Each region has two availability zones and each zone supports either Ivy Bridge or Sandy Bridge processors. GCE also offers a suite of tools for administrators to create advanced networks on the regional level. 
 &lt;/p&gt;
&lt;h3 id=&#34;applications-of-compute-engine&#34;&gt;Applications Of Compute Engine&lt;/h3&gt;
&lt;p&gt;Below are some of the use-cases or applications of the Google compute engine:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Virtual Machine (VM) migration to Compute Engine:&lt;/strong&gt; It provides tools to fast-track the migration process from on-premise or other clouds to GCP. If a user is starting with the public cloud, then they can leverage these tools to seamlessly transfer existing applications from their data center, AWS, or Azure to GCP. Users can have their applications running on Compute Engine within minutes while the data migrate transparently in the background.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Genomics Data Processing:&lt;/strong&gt; Processing genomic data is computationally-intensive because the information is enormous with vast sets of sequencing. With the Compute Engine’s potentials, users can process such large data sets. The platform is not only flexible but also scalable when it comes to processing genomic sequences.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BYOL or Bring Your Own License images:&lt;/strong&gt; A Compute Engine can help you run Windows apps in GCP by bringing their licenses to the platform as either license-included images or sole-tenant nodes. When users migrate to GCP, they can flexibly optimize their license and promote the bottom line.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;advantages-of-compute-engine&#34;&gt;Advantages Of Compute Engine&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Storage Efficiency:&lt;/strong&gt; The persistent disks support up to 257 TB of storage which is more than 10 times higher than what Amazon Elastic Block Storage (EBS) can accommodate. The organizations that require more scalable storage options can go for Compute Engine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cost:&lt;/strong&gt; Within the GCP ecosystem, users pay only for the computing time that they have consumed. The per-second billing plan is used by the Google compute engine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stability:&lt;/strong&gt; It offers more stable services because of its ability to provide live migration of VMs between the hosts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Backups:&lt;/strong&gt; Google Cloud Platform has a robust, inbuilt, and redundant backup system. The Compute Engine uses this system for flagship products like Search Engine and Gmail.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; It makes reservations to help ensure that applications have the capacity they need as they scale.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easy Integration:&lt;/strong&gt; It allows to easily integrate with other Google Cloud services like AI/ML and data analytics.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Security:&lt;/strong&gt; Google Compute Engine is a more secure and safe place for cloud applications.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about Google Compute Engine from the official &lt;a href=&#34;https://cloud.google.com/compute/docs&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Explore Google Compute Engine with this &lt;a href=&#34;https://codelabs.developers.google.com/codelabs/cloud-compute-engine#0&#34;&gt;codelab&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Nginx in GCP</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/n/nginx/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/n/nginx/</guid>
      <description>
        
        
        &lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;https://github.com/DSC-VJTI/a-z-cloud/raw/main/content/docs/N/nginx-gcp.jpg&#34; a;t=&#34;Nginx in Google Cloud Platform&#34;&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;NGINX brings power and control to your Google Cloud Platform (GCP) environment so you can operate services and deliver content at the high standard your customers and developers demand.&lt;/p&gt;
&lt;p&gt;NGINX Plus operates stand‑alone or can integrate with GCP services – such as existing load balancing solutions – to reduce your application delivery and management costs. NGINX Plus provides enterprise‑grade features such as session persistence, configuration via API, and active health checks so that you can add advanced application load balancing, monitoring, and management to your GCP application stack. Use Packer, Terraform, and NGINX Plus to implement high‑availability, all‑active, autoscaling solutions on Google Compute Engine.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;This &lt;a href=&#34;https://cloud.google.com/community/tutorials/https-load-balancing-nginx&#34;&gt;article&lt;/a&gt; gives an overview of how Nginx can be used in Load Balancing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Read more about &lt;a href=&#34;https://www.nginx.com/partners/google-cloud-platform/&#34;&gt;Nginx in GCP&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: OpenMetrics</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/o/openmetrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/o/openmetrics/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Creating OpenMetrics within CNCF was a given.&lt;/p&gt;
&lt;p&gt;- Richard &amp;ldquo;RichiH&amp;rdquo; Hartmann, director of community at Grafana Labs and OpenMetrics founder.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;what-is-openmetrics&#34;&gt;What is OpenMetrics?&lt;/h3&gt;
&lt;p&gt;It specifies the de-facto standard for transmitting cloud-native metrics at scale, with support for both text representation and Protocol Buffers. OpenMetrics is a Cloud Native Computing Foundation sandbox project.
OpenMetrics creates an open standard for transmitting cloud-native metrics at scale. It acts as an open standard for Prometheus and is the officially supported exposition format for the project and compatible solutions.&lt;/p&gt;
&lt;p&gt;Metrics are a specific kind of telemetry data, and when combined with logs and traces, provide a comprehensive view of the performance of cloud native applications.&lt;/p&gt;
&lt;p&gt;OpenMetrics was spun out of Prometheus to provide a specification and de-facto standard format for metrics.&lt;/p&gt;
&lt;p&gt;It is used or supported by most CNCF projects and many wider cloud native ecosystem projects. Furthermore, any changes are considered closely with Cortex, Prometheus, Kubernetes, and Thanos.&lt;/p&gt;
&lt;p&gt;OpenMetrics is used in production by many large enterprises, including GitLab, DoorDash, Grafana Labs, Chronosphere, Everquote, and SoundCloud. &lt;/p&gt;
&lt;p&gt;OpenMetrics stems from the stats formats used inside of Prometheus and Google’s Monarch time-series infrastructure, which underpins both Stackdriver and internal monitoring applications.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about OpenMetrics from the official &lt;a href=&#34;https://openmetrics.io/&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Learn more about Prometheus from the official &lt;a href=&#34;https://prometheus.io/&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: OpenTelemetry</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/o/opentelemetry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/o/opentelemetry/</guid>
      <description>
        
        
        &lt;h3 id=&#34;what-is-opentelemetry&#34;&gt;What is OpenTelemetry?&lt;/h3&gt;
&lt;p&gt;OpenTelemetry (also referred to as OTel) is an open-source observability framework made up of a collection of tools, APIs, and SDKs. Otel enables IT teams to instrument, generate, collect, and export telemetry data for analysis and to understand software performance and behavior.&lt;/p&gt;
&lt;p&gt;Having a common format for how observability data is collected and sent is where OpenTelemetry comes into play. As a Cloud Native Computing Foundation (CNCF) incubating project, OTel aims to provide unified sets of vendor-agnostic libraries and APIs — mainly for collecting data and transferring it somewhere. Since the project’s start, many vendors have come on board to help make rich data collection easier and more consumable.&lt;/p&gt;
&lt;h3 id=&#34;what-is-telemetry-data&#34;&gt;What is telemetry data?&lt;/h3&gt;
&lt;p&gt;Capturing data is critical to understanding how your applications and infrastructure are performing at any given time. This information is gathered from remote, often inaccessible points within your ecosystem and processed by some sort of tool or equipment. Monitoring begins here. The data is incredibly plentiful and difficult to store over long periods due to capacity limitations — a reason why private and public cloud storage services have been a boon to DevOps teams.&lt;/p&gt;
&lt;p&gt;Logs, metrics, and traces make up the bulk of all telemetry data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Logs&lt;/strong&gt; are important because you’ll naturally want an event-based record of any notable anomalies across the system. Structured, unstructured, or in plain text, these readable files can tell you the results of any transaction involving an endpoint within your multicloud environment. However, not all logs are inherently reviewable — a problem that’s given rise to external log analysis tools.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Metrics&lt;/strong&gt; are numerical data points represented as counts or measures that are often calculated or aggregated over a period of time. Metrics originate from several sources including infrastructure, hosts, and third-party sources. While logs aren’t always accessible, most metrics tend to be reachable via query. Timestamps, values, and even event names can preemptively uncover a growing problem that needs remediation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Traces&lt;/strong&gt; are the act of following a process (for example, an API request or other system activity) from start to finish, showing how services connect. Keeping a watch over this pathway is critical to understanding how your ecosystem works, if it’s working effectively, and if any troubleshooting is necessary. Span data is a hallmark of tracing — which includes information such as unique identifiers, operation names, timestamps, logs, events, and indexes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-does-opentelemetry-work&#34;&gt;How does OpenTelemetry work?&lt;/h3&gt;
&lt;p&gt;OTel is a specialized protocol for collecting telemetry data and exporting it to a target system. Since the CNCF project itself is open source, the end goal is making data collection more system-agnostic than it currently is. But how is that data generated?&lt;/p&gt;
&lt;p&gt;The data life cycle has multiple steps from start to finish. Here are the steps the solution takes, and the data it generates along the way:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Instruments your code with APIs, telling system components what metrics to gather and how to gather them&lt;/li&gt;
&lt;li&gt;Pools the data using SDKs, and transports it for processing and exporting&lt;/li&gt;
&lt;li&gt;Breaks down the data, samples it, filters it to reduce noise or errors, and enriches it using multi-source contextualization&lt;/li&gt;
&lt;li&gt;Converts and exports the data&lt;/li&gt;
&lt;li&gt;Conducts more filtering in time-based batches, then moves the data onward to a predetermined backend.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;opentelemetry-components&#34;&gt;OpenTelemetry components&lt;/h3&gt;
&lt;p&gt;OTel consists of a few different components as depicted in the following figure. Let’s take a high-level look at each one from left to right:&lt;/p&gt;
&lt;p align = &#34;center&#34;&gt;
&lt;img src = &#34;https://marvel-b1-cdn.bc0a.com/f00000000236551/dt-cdn.net/wp-content/uploads/2020/07/OT.png&#34; alt=&#34;OpenTelemetry Components&#34; &gt;
&lt;/p&gt;
&lt;p align = &#34;center&#34;&gt;
OpenTelemetry Components
&lt;/p&gt;   
&lt;br/&gt;
&lt;h5 id=&#34;apis&#34;&gt;APIs&lt;/h5&gt;
&lt;p&gt;These are core components and language-specific (such as Java, Python, .Net, and so on). APIs provide the basic “plumbing” for your application.&lt;/p&gt;
&lt;h5 id=&#34;sdk&#34;&gt;SDK&lt;/h5&gt;
&lt;p&gt;This is also a language-specific component and is the middleman that provides the bridge between the APIs and the exporter. The SDK allows for additional configuration, such as request filtering and transaction sampling.&lt;/p&gt;
&lt;h5 id=&#34;in-process-exporter&#34;&gt;In-process exporter&lt;/h5&gt;
&lt;p&gt;This allows you to configure which backend(s) you want it sent to. The exporter decouples the instrumentation from the backend configuration. This makes it easy to switch backends without the pain of re-instrumenting your code.&lt;/p&gt;
&lt;h5 id=&#34;collector&#34;&gt;Collector&lt;/h5&gt;
&lt;p&gt;The collector receives, processes, and exports telemetry data. While not technically required, it is an extremely useful component to the OpenTelemetry architecture because it allows greater flexibility for receiving and sending the application telemetry to the backend(s).
The collector has two deployment models:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;An agent that resides on the same host as the application (for example, binary, DaemonSet, sidecar, and so on)&lt;/li&gt;
&lt;li&gt;A standalone process completely separate from the application
Since the collector is just a specification for collecting and sending telemetry, it still requires a backend to receive and store the data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;benefits-of-opentelemetry&#34;&gt;Benefits of OpenTelemetry&lt;/h3&gt;
&lt;p&gt;OTel provides a de facto standard for adding observable instrumentation to cloud-native applications. This means companies don’t need to spend valuable time developing a mechanism for collecting critical application data and can spend more time delivering new features instead.
It’s akin to how Kubernetes became the standard for container orchestration. This broad adoption has made it easier for organizations to implement container deployments since they don’t need to build their own enterprise-grade orchestration platform. Using Kubernetes as the analog for what it can become, it’s easy to see the benefits it can provide to the entire industry.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about OpenTelemetry from the official &lt;a href=&#34;https://opentelemetry.io/docs/&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: OpenTelemetry</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/t/opentelemetry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/t/opentelemetry/</guid>
      <description>
        
        
        &lt;h3 id=&#34;what-is-opentelemetry&#34;&gt;What is OpenTelemetry?&lt;/h3&gt;
&lt;p&gt;OpenTelemetry (also referred to as OTel) is an open-source observability framework made up of a collection of tools, APIs, and SDKs. Otel enables IT teams to instrument, generate, collect, and export telemetry data for analysis and to understand software performance and behavior.&lt;/p&gt;
&lt;p&gt;Having a common format for how observability data is collected and sent is where OpenTelemetry comes into play. As a Cloud Native Computing Foundation (CNCF) incubating project, OTel aims to provide unified sets of vendor-agnostic libraries and APIs — mainly for collecting data and transferring it somewhere. Since the project’s start, many vendors have come on board to help make rich data collection easier and more consumable.&lt;/p&gt;
&lt;h3 id=&#34;what-is-telemetry-data&#34;&gt;What is telemetry data?&lt;/h3&gt;
&lt;p&gt;Capturing data is critical to understanding how your applications and infrastructure are performing at any given time. This information is gathered from remote, often inaccessible points within your ecosystem and processed by some sort of tool or equipment. Monitoring begins here. The data is incredibly plentiful and difficult to store over long periods due to capacity limitations — a reason why private and public cloud storage services have been a boon to DevOps teams.&lt;/p&gt;
&lt;p&gt;Logs, metrics, and traces make up the bulk of all telemetry data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Logs&lt;/strong&gt; are important because you’ll naturally want an event-based record of any notable anomalies across the system. Structured, unstructured, or in plain text, these readable files can tell you the results of any transaction involving an endpoint within your multicloud environment. However, not all logs are inherently reviewable — a problem that’s given rise to external log analysis tools.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Metrics&lt;/strong&gt; are numerical data points represented as counts or measures that are often calculated or aggregated over a period of time. Metrics originate from several sources including infrastructure, hosts, and third-party sources. While logs aren’t always accessible, most metrics tend to be reachable via query. Timestamps, values, and even event names can preemptively uncover a growing problem that needs remediation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Traces&lt;/strong&gt; are the act of following a process (for example, an API request or other system activity) from start to finish, showing how services connect. Keeping a watch over this pathway is critical to understanding how your ecosystem works, if it’s working effectively, and if any troubleshooting is necessary. Span data is a hallmark of tracing — which includes information such as unique identifiers, operation names, timestamps, logs, events, and indexes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-does-opentelemetry-work&#34;&gt;How does OpenTelemetry work?&lt;/h3&gt;
&lt;p&gt;OTel is a specialized protocol for collecting telemetry data and exporting it to a target system. Since the CNCF project itself is open source, the end goal is making data collection more system-agnostic than it currently is. But how is that data generated?&lt;/p&gt;
&lt;p&gt;The data life cycle has multiple steps from start to finish. Here are the steps the solution takes, and the data it generates along the way:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Instruments your code with APIs, telling system components what metrics to gather and how to gather them&lt;/li&gt;
&lt;li&gt;Pools the data using SDKs, and transports it for processing and exporting&lt;/li&gt;
&lt;li&gt;Breaks down the data, samples it, filters it to reduce noise or errors, and enriches it using multi-source contextualization&lt;/li&gt;
&lt;li&gt;Converts and exports the data&lt;/li&gt;
&lt;li&gt;Conducts more filtering in time-based batches, then moves the data onward to a predetermined backend.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;opentelemetry-components&#34;&gt;OpenTelemetry components&lt;/h3&gt;
&lt;p&gt;OTel consists of a few different components as depicted in the following figure. Let’s take a high-level look at each one from left to right:&lt;/p&gt;
&lt;p align = &#34;center&#34;&gt;
&lt;img src = &#34;https://marvel-b1-cdn.bc0a.com/f00000000236551/dt-cdn.net/wp-content/uploads/2020/07/OT.png&#34; alt=&#34;OpenTelemetry Components&#34; &gt;
&lt;/p&gt;
&lt;p align = &#34;center&#34;&gt;
OpenTelemetry Components
&lt;/p&gt;   
&lt;br/&gt;
&lt;h5 id=&#34;apis&#34;&gt;APIs&lt;/h5&gt;
&lt;p&gt;These are core components and language-specific (such as Java, Python, .Net, and so on). APIs provide the basic “plumbing” for your application.&lt;/p&gt;
&lt;h5 id=&#34;sdk&#34;&gt;SDK&lt;/h5&gt;
&lt;p&gt;This is also a language-specific component and is the middleman that provides the bridge between the APIs and the exporter. The SDK allows for additional configuration, such as request filtering and transaction sampling.&lt;/p&gt;
&lt;h5 id=&#34;in-process-exporter&#34;&gt;In-process exporter&lt;/h5&gt;
&lt;p&gt;This allows you to configure which backend(s) you want it sent to. The exporter decouples the instrumentation from the backend configuration. This makes it easy to switch backends without the pain of re-instrumenting your code.&lt;/p&gt;
&lt;h5 id=&#34;collector&#34;&gt;Collector&lt;/h5&gt;
&lt;p&gt;The collector receives, processes, and exports telemetry data. While not technically required, it is an extremely useful component to the OpenTelemetry architecture because it allows greater flexibility for receiving and sending the application telemetry to the backend(s).
The collector has two deployment models:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;An agent that resides on the same host as the application (for example, binary, DaemonSet, sidecar, and so on)&lt;/li&gt;
&lt;li&gt;A standalone process completely separate from the application
Since the collector is just a specification for collecting and sending telemetry, it still requires a backend to receive and store the data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;benefits-of-opentelemetry&#34;&gt;Benefits of OpenTelemetry&lt;/h3&gt;
&lt;p&gt;OTel provides a de facto standard for adding observable instrumentation to cloud-native applications. This means companies don’t need to spend valuable time developing a mechanism for collecting critical application data and can spend more time delivering new features instead.
It’s akin to how Kubernetes became the standard for container orchestration. This broad adoption has made it easier for organizations to implement container deployments since they don’t need to build their own enterprise-grade orchestration platform. Using Kubernetes as the analog for what it can become, it’s easy to see the benefits it can provide to the entire industry.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about OpenTelemetry from the official &lt;a href=&#34;https://opentelemetry.io/docs/&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: OpenTracing</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/o/opentracing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/o/opentracing/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Ideas about distributed tracing and monitoring across multiple systems have certainly generated quite a buzz. It’s becoming more important than ever before to be able to see what’s going on inside our requests as they span across multiple software services. Aiming to harness this importance, the OpenTracing initiative has sprung up to help developers avoid vendor lock-in.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;what-is-distributed-tracing&#34;&gt;What Is Distributed Tracing?&lt;/h3&gt;
&lt;p&gt;Distributed tracing is a mechanism you can use to profile and monitor applications. Unlike regular tracing, distributed tracing is more suited to applications built using a microservice architecture, hence the name.&lt;/p&gt;
&lt;p&gt;Distributed tracing tracks a single request through all of its journey, from its source to its destination, unlike traditional forms of tracing which just follow a request through a single application domain.
In other words, we can say that distributed tracing is the stitching of multiple requests across multiple systems. The stitching is often done by one or more correlation IDs, and the tracing is often a set of recorded, structured log events across all the systems, stored in a central place.&lt;/p&gt;
&lt;h3 id=&#34;what-is-opentracing&#34;&gt;What is OpenTracing?&lt;/h3&gt;
&lt;p&gt;It’s a vendor-agnostic API to help developers easily instrument tracing into their code base. It’s open because no one company owns it. &lt;/p&gt;
&lt;p&gt;OpenTracing wants to form a common language around what a trace is and how to instrument them in our applications. In OpenTracing, a trace is a directed acyclic graph of Spans with References that may look like this&lt;/p&gt;
&lt;p align = &#34;center&#34;&gt;
&lt;img src = &#34;https://github.com/DSC-VJTI/a-z-cloud/raw/main/content/docs/O/1.png&#34;&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;This allows us to model how our application calls out to other applications, internal functions, asynchronous jobs, etc. All of these can be modeled as Spans, as we’ll see below.&lt;/p&gt;
&lt;p&gt;For example, if I have a consumer website where a customer places orders, I make a call to my payment system and my inventory system before asynchronously acknowledging the order. I can trace the entire order process through every system with an OpenTracing library and can render it like this:&lt;/p&gt;
&lt;p align = &#34;center&#34;&gt;
&lt;img src = &#34;https://github.com/DSC-VJTI/a-z-cloud/raw/main/content/docs/O/2.png&#34;&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;Each one of these bracketed blocks is a Span representing a separate software system communicating over messaging or HTTP.&lt;/p&gt;
&lt;h3 id=&#34;terminology&#34;&gt;Terminology&lt;/h3&gt;
&lt;p&gt;Let’s talk a bit about the components of the OpenTracing API.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tracer&lt;/strong&gt;    &lt;br&gt;
This tracer is the entry point into the tracing API. It gives us the ability to create Spans. It also lets us extract tracing information from external sources and inject information to external destinations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Span&lt;/strong&gt;    &lt;br&gt;
This represents a unit of work in the Trace. For example, a web request that initiates a new Trace is called the root Span. If it calls out to another web service, that HTTP request would be wrapped within a new child Span. Spans carry around a set of tags of information pertinent to the request being carried out. You can also log events within the context of a Span. They can support more complex workflows than web requests, such as asynchronous messaging. They have timestamps attached to them so we can easily construct a timeline of events for the Trace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SpanContext&lt;/strong&gt;   &lt;br&gt;
The SpanContext is the serializable form of a Span. It lets Span information transfer easily across the wire to other systems.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;      &lt;br&gt;
So far, Spans can connect to each other via two types of relationship: ChildOf and FollowsFrom. ChildOf Spans are spans like in our previous example, where our ordering website sent child requests to both our payment system and inventory system. FollowsFrom Spans are just a chain of sequential Spans. So, a FollowsFrom Span is just saying, “I started after this other Span.”&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;is-opentracing-still-in-use&#34;&gt;Is OpenTracing still in Use?&lt;/h3&gt;
&lt;p&gt;OpenTracing is an open-source CNCF (Cloud Native Computing Foundation) project which provides vendor-neutral APIs and instrumentation for distributed tracing. Although OpenTracing and OpenCensus have merged to form OpenTelemetry in early 2019, third-party libraries and frameworks like Hazelcast IMDG still come equipped with OpenTracing pre-instrumentation.&lt;/p&gt;
&lt;p&gt;OpenTracing became a CNCF project back in 2016, with the goal of providing a vendor-agnostic specification for distributed tracing, offering developers the ability to trace a request from start to finish by instrumenting their code. Then, Google made the OpenCensus project open source in 2018. This was based on Google’s Census library that was used internally for gathering traces and metrics from their distributed systems. Like the OpenTracing project, the goal of OpenCensus was to give developers a vendor-agnostic library for collecting traces and metrics.
This led to two competing tracing frameworks, which led to the informal reference “the Tracing Wars.” Usually, competition is a good thing for end-users since it breeds innovation. However, in the open-source specification world, competition can lead to poor adoption, contribution, and support.
Going back to the Kubernetes example, imagine how much more disjointed and slow-moving container adoption would be if everybody was using a different orchestration solution. To avoid this, it was announced at KubeCon 2019 in Barcelona that the OpenTracing and OpenCensus projects would converge into one project called OpenTelemetry and join the CNCF.&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about OpenTracing from the official &lt;a href=&#34;https://opentracing.io/&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Visual Inspection AI</title>
      <link>https://dsc-vjti.github.io/a-z-cloud/docs/q/visual_inspection_ai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-vjti.github.io/a-z-cloud/docs/q/visual_inspection_ai/</guid>
      <description>
        
        
        &lt;p&gt;The Google Cloud Visual Inspection AI solution automates visual inspection tasks using a set of AI and computer vision technologies that enable manufacturers to transform quality control processes by automatically detecting product defects.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a demo use-case in the chip manufacturing industry:&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;https://github.com/rakesh-201/a-z-cloud-1/blob/main/content/docs/Q/Demo.gif?raw=true&#34; a;t=&#34;Demo&#34;&gt;
&lt;/p&gt;
&lt;h3 id=&#34;other-use-cases&#34;&gt;Other Use-cases&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Automotive manufacturing&lt;/strong&gt;: Paint shop surface inspection, body shop welding seam inspection, press shop inspection (scratch, dents, cracks, staining), foundry engine block inspection (cracks, deformation, anomaly)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Semiconductor manufacturing&lt;/strong&gt;: Wafer level anomaly and defect localization, die crack inspection, pre-place inspection, SoC packaging inspection, board assembly inspection&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Electronics manufacturing&lt;/strong&gt;: Defective or missing printed circuit board (PCB) components (screw, spring, foam, connector, shield, etc.), PCB soldering and gluing (insufficient solder, Icicle, shift, exceeding tin, etc.), product surface check (glue spill, mesh deformation, scratches, bubbles, etc.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;General-purpose manufacturing&lt;/strong&gt;: Packaging and label inspection, fabric inspection (mesh, tear, yarn), metal and plastic welding seam inspection, surface inspection&lt;/p&gt;
&lt;h3 id=&#34;learn&#34;&gt;Learn&lt;/h3&gt;
&lt;p&gt;Learn more about &lt;a href=&#34;https://cloud.google.com/blog/products/ai-machine-learning/improve-manufacturing-quality-control-with-visual-inspection-ai&#34;&gt;Visual Inspection AI&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
